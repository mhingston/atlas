# Atlas Gateway Environment Configuration

# LLM Provider
# Options: mock, openai, anthropic, ollama, or custom (for any AI SDK provider)
ATLAS_LLM_PROVIDER=mock

# Fallback behavior when provider is unavailable
# Options: mock, error
ATLAS_LLM_PROVIDER_FALLBACK=mock

# OpenAI Configuration (if using openai provider)
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration (if using anthropic provider)
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (if using ollama provider)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2

# Custom Provider Configuration (for any AI SDK provider)
# ATLAS_LLM_PROVIDER=custom
# ATLAS_LLM_PACKAGE=@ai-sdk/google
# ATLAS_LLM_FACTORY=createGoogleGenerativeAI
# ATLAS_LLM_MODEL=gemini-pro
# ATLAS_LLM_API_KEY=...

# Harness Runtime (for code assistance workflows)
# Options: true, false
# Harnesses are configured in gateway.routing.json
ATLAS_HARNESS_ENABLED=false

# Database
ATLAS_DB_PATH=data/atlas.db

# Server
PORT=3000

# Workflow scheduling
# Use cron/systemd to call the CLI or HTTP API for scheduled workflows.
